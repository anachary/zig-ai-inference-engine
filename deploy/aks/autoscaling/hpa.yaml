# Horizontal Pod Autoscaler for Zig AI Shards
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: zig-ai-shard-hpa
  namespace: zig-ai
  labels:
    app.kubernetes.io/name: zig-ai
    app.kubernetes.io/component: shard
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: zig-ai-shard
  minReplicas: 2
  maxReplicas: 16
  metrics:
  # CPU-based scaling
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  # Memory-based scaling
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  # GPU-based scaling (custom metric)
  - type: Pods
    pods:
      metric:
        name: nvidia_gpu_utilization
      target:
        type: AverageValue
        averageValue: "80"
  # Inference requests per second
  - type: Pods
    pods:
      metric:
        name: inference_requests_per_second
      target:
        type: AverageValue
        averageValue: "10"
  # Queue depth metric
  - type: Pods
    pods:
      metric:
        name: inference_queue_depth
      target:
        type: AverageValue
        averageValue: "5"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 minutes
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Min
    scaleUp:
      stabilizationWindowSeconds: 60   # 1 minute
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
      - type: Pods
        value: 4
        periodSeconds: 60
      selectPolicy: Max

---
# Horizontal Pod Autoscaler for Coordinator (if needed)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: zig-ai-coordinator-hpa
  namespace: zig-ai
  labels:
    app.kubernetes.io/name: zig-ai
    app.kubernetes.io/component: coordinator
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: zig-ai-coordinator
  minReplicas: 1
  maxReplicas: 3
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 80
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 85
  # Active connections metric
  - type: Pods
    pods:
      metric:
        name: active_connections
      target:
        type: AverageValue
        averageValue: "500"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 600  # 10 minutes
      policies:
      - type: Pods
        value: 1
        periodSeconds: 300
    scaleUp:
      stabilizationWindowSeconds: 30   # 30 seconds
      policies:
      - type: Pods
        value: 1
        periodSeconds: 60

---
# Vertical Pod Autoscaler for Shards (optional)
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: zig-ai-shard-vpa
  namespace: zig-ai
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: zig-ai-shard
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: shard
      minAllowed:
        cpu: "4"
        memory: "16Gi"
      maxAllowed:
        cpu: "32"
        memory: "128Gi"
      controlledResources: ["cpu", "memory"]
      controlledValues: RequestsAndLimits

---
# Pod Disruption Budget for Shards
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: zig-ai-shard-pdb
  namespace: zig-ai
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/name: zig-ai-shard

---
# Pod Disruption Budget for Coordinator
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: zig-ai-coordinator-pdb
  namespace: zig-ai
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: zig-ai-coordinator

---
# Custom Resource for Azure-specific scaling
apiVersion: v1
kind: ConfigMap
metadata:
  name: azure-scaling-config
  namespace: zig-ai
data:
  scaling.yaml: |
    azure:
      scaling:
        # Azure Container Instances burst scaling
        aci_burst:
          enabled: true
          max_instances: 10
          scale_up_threshold: 90  # CPU percentage
          scale_down_threshold: 30
          scale_up_cooldown: "2m"
          scale_down_cooldown: "5m"
          
        # Azure Spot Instances for cost optimization
        spot_instances:
          enabled: true
          max_spot_percentage: 50
          eviction_policy: "Delete"
          
        # Azure VM Scale Sets integration
        vmss:
          enabled: false
          scale_set_name: "zig-ai-vmss"
          min_instances: 2
          max_instances: 20
          
        # Predictive scaling based on Azure Monitor
        predictive:
          enabled: true
          look_ahead_minutes: 15
          metrics:
            - name: "inference_requests"
              weight: 0.6
            - name: "queue_depth"
              weight: 0.4
              
        # Cost-aware scaling
        cost_optimization:
          enabled: true
          max_hourly_cost: 100  # USD
          prefer_spot_instances: true
          scale_down_aggressively: true
          
        # Regional scaling preferences
        regions:
          primary: "eastus"
          secondary: ["westus2", "centralus"]
          cross_region_scaling: false

---
# ServiceMonitor for custom metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: zig-ai-metrics
  namespace: zig-ai
  labels:
    app.kubernetes.io/name: zig-ai
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: zig-ai
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    honorLabels: true

---
# PrometheusRule for custom alerts
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: zig-ai-scaling-alerts
  namespace: zig-ai
spec:
  groups:
  - name: zig-ai.scaling
    rules:
    - alert: HighInferenceLatency
      expr: histogram_quantile(0.95, inference_duration_seconds) > 5
      for: 2m
      labels:
        severity: warning
        component: shard
      annotations:
        summary: "High inference latency detected"
        description: "95th percentile inference latency is {{ $value }}s"
        
    - alert: ShardMemoryPressure
      expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) > 0.9
      for: 5m
      labels:
        severity: critical
        component: shard
      annotations:
        summary: "Shard memory pressure"
        description: "Shard {{ $labels.pod }} memory usage is {{ $value | humanizePercentage }}"
        
    - alert: GPUUtilizationHigh
      expr: nvidia_gpu_utilization > 95
      for: 3m
      labels:
        severity: warning
        component: shard
      annotations:
        summary: "High GPU utilization"
        description: "GPU utilization is {{ $value }}% on {{ $labels.pod }}"
        
    - alert: InferenceQueueBacklog
      expr: inference_queue_depth > 20
      for: 1m
      labels:
        severity: warning
        component: coordinator
      annotations:
        summary: "Inference queue backlog"
        description: "Queue depth is {{ $value }} requests"
        
    - alert: ShardUnavailable
      expr: up{job="zig-ai-shard"} == 0
      for: 1m
      labels:
        severity: critical
        component: shard
      annotations:
        summary: "Shard unavailable"
        description: "Shard {{ $labels.instance }} is down"
